# ğŸ“Š School Graduation Rate Analysis

## ğŸ¯ Project Overview
This started as a **group project**: we collected data and first ran **ANOVA/linear regression in R**, producing facet plots of state-level graduation rates.
I then **ported the workflow to Python**, replicating the original analysis.
Finally, I extended the work with **machine learning models (Logistic Regression vs Random Forest)** to predict high school graduation rates.
Because the dataset had many missing values, random train/test splits gave misleading results. To handle this, I designed a more robust **Expanding Time Split** (â‰¤t-1 â†’ t) validation scheme.

## ğŸ—ï¸ Project Structure
```
school/
â”œâ”€ data/
â”‚   â””â”€ school.csv                 # raw dataset (state Ã— year Ã— metrics)
â”œâ”€ legacy/
â”‚   â”œâ”€ README.md                  # original R notes
â”‚   â””â”€ drop_rate.R                # initial ANOVA/linear regression in R
â”œâ”€ outputs/
â”‚   â”œâ”€ artifacts/                 # machine learning artifacts (auto-generated)
â”‚   â”‚   â”œâ”€ Logit_by_year_*.csv    # yearly metrics for Logistic Regression
â”‚   â”‚   â”œâ”€ RF_by_year_*.csv       # yearly metrics for Random Forest
â”‚   â”‚   â”œâ”€ model_Logit_*.joblib   # trained scikit-learn pipeline (Logit)
â”‚   â”‚   â”œâ”€ model_RF_*.joblib      # trained scikit-learn pipeline (RF)
â”‚   â”‚   â””â”€ manifest_*.json        # config & artifact manifest
â”‚   â”œâ”€ Factors_Influencing_Fradutation_Rates_by_Year_and_State.PNG
â”‚   â””â”€ anava(RCD)_and_linearRegression.PNG
â””â”€ src/
    â”œâ”€ analysis.py                 # exploratory analysis
    â””â”€ school_ml.py                # ML pipeline (Logit vs RF, Expanding CV)
```
## ğŸ“Š Data
**Source**: data/school.csv
**Features**: alcohol, bully, cyberbully, weapon_state, year
**Target**: Adjusted Cohort Graduation Rate (ACGR, %)
**Binary classification**: ACGR â‰¥ 85% â†’ 1, else 0

## ğŸ”¬ Method
1. **Exploratory Analysis**
- Initial R analysis: facet plots and ANOVA/linear regression (outputs/*.PNG).
2. **Python Port**
- Data cleaning, reshaping (long â†” wide), and replication of R outputs.
3. **Machine Learning**
- Models: Logistic Regression (baseline, interpretable), Random Forest Classifier (non-linear).
- Validation: Expanding split (â‰¤t-1 years for training, predict year t).
- Missing values: handled with SimpleImputer(strategy='median').

## ğŸ“‹ Results
- **Logistic Regression**
   - Avg Accuracy â‰ˆ 0.82, F1 â‰ˆ 0.84, AUC â‰ˆ 0.92
   - Stable, interpretable (coefficients by state/feature).
- **Random Forest**
  - Avg Accuracy â‰ˆ 0.69, F1 â‰ˆ 0.69, AUC â‰ˆ 0.75
  - Performs well in later years but unstable in early years (AUC ~0.5 in 2012â€“2014).
- **Conclusion**: Logistic Regression is the most reliable overall. Random Forest provides supplementary insights but suffers from instability with sparse early data.

## ğŸ¯ Artifacts
All experiment outputs are stored in `outputs/artifacts/`:
- `*_by_year_*.csv|pkl`: yearly evaluation metrics.
- `model_*.joblib`: trained pipelines.
- `manifest_*.json`: configuration + artifact log.

## â“ How to Reproduce
cd src
python school_ml.py

Results will be saved automatically under `../outputs/artifacts/`.

## â­ï¸ Next Steps
- Add **lag features** (e.g., previous yearâ€™s alcohol/bully levels â†’ current ACGR).
- Address **class imbalance** (threshold tuning, resampling).
- Benchmark **other ML models** (Gradient Boosting, XGBoost, etc.).
